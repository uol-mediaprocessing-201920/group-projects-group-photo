{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkz5lwfrfStT",
        "colab_type": "code",
        "outputId": "29105afc-4e0f-43ef-a00f-1503880a1912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy.spatial as spatial\n",
        "from scipy.spatial.distance import euclidean as euclid_distance\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# upload pictures\n",
        "!wget -q https://github.com/uol-mediaprocessing/group-projects-group-photo/raw/master/pictures/group_2/index.txt -O group_2.txt\n",
        "!mkdir group_2\n",
        "\n",
        "!xargs -i -a group_2.txt wget -q https://github.com/uol-mediaprocessing/group-projects-group-photo/raw/master/pictures/group_2/{} -O group_2/{}\n",
        "!ls -lah group_2\n",
        "\n",
        "path = './group_2'\n",
        "\n",
        "files = os.listdir(path)\n",
        "files = list(map(lambda f: path + '/' + f, files))\n",
        "print(files)\n",
        "\n",
        "imgs = list(map(cv2.imread, files))\n",
        "\n",
        "# get models\n",
        "!wget -q  https://github.com/uol-mediaprocessing/group-projects-group-photo/raw/master/shape_predictor_68_face_landmarks.dat.bz2 -O shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget -q https://github.com/uol-mediaprocessing/group-projects-group-photo/raw/master/dlib_face_recognition_resnet_model_v1.dat.bz2\n",
        "!bzip2 -d dlib_face_recognition_resnet_model_v1.dat.bz2\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/3.4/data/haarcascades/haarcascade_smile.xml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 40M\n",
            "drwxr-xr-x 2 root root 4.0K Jan 23 11:01 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan 23 11:00 ..\n",
            "-rw-r--r-- 1 root root 3.7M Jan 23 11:00 IMG_20191112_111241.jpg\n",
            "-rw-r--r-- 1 root root 3.6M Jan 23 11:00 IMG_20191112_111244.jpg\n",
            "-rw-r--r-- 1 root root 4.0M Jan 23 11:00 IMG_20191112_111256.jpg\n",
            "-rw-r--r-- 1 root root 3.9M Jan 23 11:01 IMG_20191112_111257.jpg\n",
            "-rw-r--r-- 1 root root 3.8M Jan 23 11:01 IMG_20191112_111300.jpg\n",
            "-rw-r--r-- 1 root root 4.2M Jan 23 11:01 IMG_20191112_111301.jpg\n",
            "-rw-r--r-- 1 root root 3.8M Jan 23 11:01 IMG_20191112_111313.jpg\n",
            "-rw-r--r-- 1 root root 3.3M Jan 23 11:01 IMG_20191112_111315.jpg\n",
            "-rw-r--r-- 1 root root 3.4M Jan 23 11:01 IMG_20191112_111327.jpg\n",
            "-rw-r--r-- 1 root root 3.5M Jan 23 11:01 IMG_20191112_111330.jpg\n",
            "-rw-r--r-- 1 root root 3.3M Jan 23 11:01 IMG_20191112_111332.jpg\n",
            "['./group_2/IMG_20191112_111327.jpg', './group_2/IMG_20191112_111313.jpg', './group_2/IMG_20191112_111300.jpg', './group_2/IMG_20191112_111244.jpg', './group_2/IMG_20191112_111257.jpg', './group_2/IMG_20191112_111330.jpg', './group_2/IMG_20191112_111332.jpg', './group_2/IMG_20191112_111315.jpg', './group_2/IMG_20191112_111301.jpg', './group_2/IMG_20191112_111256.jpg', './group_2/IMG_20191112_111241.jpg']\n",
            "--2020-01-23 11:01:24--  https://raw.githubusercontent.com/opencv/opencv/3.4/data/haarcascades/haarcascade_smile.xml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188506 (184K) [text/plain]\n",
            "Saving to: ‘haarcascade_smile.xml’\n",
            "\n",
            "haarcascade_smile.x 100%[===================>] 184.09K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-01-23 11:01:24 (5.25 MB/s) - ‘haarcascade_smile.xml’ saved [188506/188506]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTxi45Oqer3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "class Person:\n",
        "  def __init__(self, id):\n",
        "    self.id = id\n",
        "    self.faces = []\n",
        "\n",
        "  def faceVectorMatches(self, vector):\n",
        "    return euclid_distance(self.id,vector) < 0.6\n",
        "\n",
        "  def normalize_scores(self):\n",
        "    for score_name in [\"orientation\", \"eyes\", \"mouth\"]:\n",
        "      attr_name = \"score_\" + score_name\n",
        "      max = float(\"-inf\")\n",
        "      for face in self.faces:\n",
        "        score = getattr(face, attr_name)\n",
        "        if score > max:\n",
        "          max = score\n",
        "      for face in self.faces:\n",
        "        if max == 0: break\n",
        "        score = getattr(face, attr_name) / max\n",
        "        setattr(face, attr_name, score)\n",
        "      for face in self.faces:\n",
        "        face.calc_score_all()\n",
        "\n",
        "  def getFaceFromPic(self,idx):\n",
        "    return next((face for face in self.faces if face.picture_index == idx),None)\n",
        "      \n",
        "\n",
        "class Face:\n",
        "  def __init__(self, picture_data, picture_index, landmarks,coords):\n",
        "    self.picture_data = picture_data\n",
        "    self.picture_index = picture_index\n",
        "    self.mask = None\n",
        "    self.convexHull = None\n",
        "    self.triangles = None\n",
        "    self.landmarks = landmarks\n",
        "    self.score_orientation = None\n",
        "    self.score_eyes = None\n",
        "    self.score_mouth = None\n",
        "    self.score_all = None\n",
        "    self.coords = coords\n",
        "\n",
        "  def landmarksToFullSize(self):\n",
        "    landmarksList = []\n",
        "    for x in shape_to_np(landmarks):\n",
        "      landmarksList.append((x[0]+self.coords.left(),x[1]+self.coords.top()))\n",
        "    return np.array(landmarksList)\n",
        "    \n",
        "  def show(self):\n",
        "    cv2_imshow(self.picture_data)\n",
        "\n",
        "  def calc_face_mask(self):\n",
        "    height, width, _ = self.picture_data.shape\n",
        "    mask = np.zeros((height,width,1),dtype= np.uint8)\n",
        "    landmark_points = shape_to_np(self.landmarks)\n",
        "    self.convexHull = cv2.convexHull(landmark_points)\n",
        "    #cv2.polylines(img, [convexhull], True, (255, 0, 0), 3)\n",
        "    cv2.fillConvexPoly(mask, self.convexHull, (255,255,255))\n",
        "    self.mask = cv2.bitwise_and(self.picture_data, self.picture_data, mask=mask)\n",
        "\n",
        "  def delauney_triangulation(self):\n",
        "    rect = cv2.boundingRect(self.convexHull)\n",
        "    subdiv = cv2.Subdiv2D(rect)\n",
        "    landmark_points = shape_to_list(self.landmarks)\n",
        "    landmark_points = landmark_points[:22]\n",
        "    subdiv.insert(landmark_points)\n",
        "    triangles = subdiv.getTriangleList()\n",
        "    self.triangles = np.array(triangles, dtype=np.int32)\n",
        "    img_copy = cv2.cvtColor(self.picture_data,cv2.COLOR_RGB2BGR).copy()\n",
        "    for triangle in triangles:\n",
        "      pt1 = (triangle[0],triangle[1])\n",
        "      pt2 = (triangle[2],triangle[3])\n",
        "      pt3 = (triangle[4],triangle[5])\n",
        "      cv2.line(img_copy,pt1,pt2,(0,0,255),1)\n",
        "      cv2.line(img_copy,pt2,pt3,(0,0,255),1)\n",
        "      cv2.line(img_copy,pt1,pt3,(0,0,255),1)\n",
        "    cv2_imshow(img_copy)\n",
        "    \n",
        "  def calc_score_eyes(self):\n",
        "    # compute the euclidean distances between the two sets of\n",
        "    # vertical eye landmarks (x, y)-coordinates\n",
        "    landmarks = shape_to_np(self.landmarks)\n",
        "    left_eye = landmarks[36:42]\n",
        "    right_eye = landmarks[42:48]\n",
        "    eyes = [left_eye,right_eye]\n",
        "    eyes_score = []\n",
        "    \n",
        "    for eye in eyes:\n",
        "      A = euclid_distance(eye[1], eye[5])\n",
        "      B = euclid_distance(eye[2], eye[4])\n",
        "\n",
        "      # compute the euclidean distance between the horizontal\n",
        "      # eye landmark (x, y)-coordinates\n",
        "      C = euclid_distance(eye[0], eye[3])\n",
        "\n",
        "      # compute the eye aspect ratio\n",
        "      ear = (A + B) / (2.0 * C)\n",
        "      # return the eye aspect ratio\n",
        "      eyes_score.append(ear)\n",
        "\n",
        "    self.score_eyes = (eyes_score[0]+eyes_score[1])/2.0\n",
        "\n",
        "\n",
        "  def calc_score_orientation(self):\n",
        "    nparray = shape_to_np(landmarks)\n",
        "    #red = (255, 0, 0)\n",
        "    #for x in range(len(nparray)):\n",
        "      #cv2.circle(picture, (nparray[x][0],nparray[x][1]), 3, red, -1)\n",
        "    # 2, 30 , 14\n",
        "    dist1 = calculateDistance(nparray[2][0],nparray[2][1],nparray[30][0],nparray[30][1])\n",
        "    dist2 = calculateDistance(nparray[14][0],nparray[14][1],nparray[30][0],nparray[30][1])\n",
        "    distRatio = abs(dist2 - dist1)\n",
        "\n",
        "    self.score_orientation = 1 / distRatio\n",
        "\n",
        "  def calc_score_mouth(self):\n",
        "    gray = cv2.cvtColor(cv2.cvtColor(self.picture_data,cv2.COLOR_RGB2BGR),cv2.COLOR_BGR2GRAY)\n",
        "    smile = face_cascade_smile.detectMultiScale3(\n",
        "        gray,\n",
        "        scaleFactor=1.8,\n",
        "        minNeighbors=20,\n",
        "        minSize=(30, 30),\n",
        "        flags = cv2.CASCADE_SCALE_IMAGE,\n",
        "        outputRejectLevels = True\n",
        "    )\n",
        "    rects = smile[0]\n",
        "    weights = smile[2]\n",
        "    if len(weights) == 1:\n",
        "      self.score_mouth = float(weights[0])\n",
        "      #print(float(weights[0]))\n",
        "    else:\n",
        "      self.score_mouth = 0\n",
        "\n",
        "  def calc_scores(self):\n",
        "    self.calc_score_orientation()\n",
        "    self.calc_score_eyes()\n",
        "    self.calc_score_mouth()\n",
        "\n",
        "    self.calc_score_all()\n",
        "    \n",
        "  # sets and return score_all, parameters are for weighting the scores\n",
        "  def calc_score_all(self, w1 = 10, w2 = 2, w3 = 4):\n",
        "    self.score_all = self.score_orientation * w1 + self.score_eyes * w2 + self.score_mouth * w3\n",
        "\n",
        "  def scores_str(self):\n",
        "    return str({\n",
        "        \"a\": round(self.score_all, 3),\n",
        "        \"o\": round(self.score_orientation, 3),\n",
        "        \"e\": round(self.score_eyes, 3),\n",
        "        \"m\": round(self.score_mouth, 3)\n",
        "    }).replace(\",\", \",\\n\")\n",
        "\n",
        "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
        "  \n",
        "  # Given a pair of triangles, find the affine transform.\n",
        "  warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
        "  \n",
        "  # Apply the Affine Transform just found to the src image\n",
        "  dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
        "\n",
        "  return dst\n",
        "\n",
        "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
        "def warpTriangle(img1, img2, t1, t2) :\n",
        "\n",
        "  # Find bounding rectangle for each triangle\n",
        "  r1 = cv2.boundingRect(np.float32([t1]))\n",
        "  r2 = cv2.boundingRect(np.float32([t2]))\n",
        "\n",
        "  # Offset points by left top corner of the respective rectangles\n",
        "  t1Rect = [] \n",
        "  t2Rect = []\n",
        "  t2RectInt = []\n",
        "\n",
        "  for i in range(0, 3):\n",
        "      t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
        "      t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
        "      t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
        "\n",
        "\n",
        "  # Get mask by filling triangle\n",
        "  mask = np.zeros((r2[3], r2[2], 3), dtype = np.float32)\n",
        "  cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);\n",
        "\n",
        "  # Apply warpImage to small rectangular patches\n",
        "  img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
        "  #img2Rect = np.zeros((r2[3], r2[2]), dtype = img1Rect.dtype)\n",
        "\n",
        "  size = (r2[2], r2[3])\n",
        "\n",
        "  img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
        "  #cv2_imshow(img2Rect)\n",
        "  img2Rect = img2Rect * mask\n",
        "  #cv2_imshow(img2Rect)\n",
        "  # Copy triangular region of the rectangular patch to the output image\n",
        "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )\n",
        "  #cv2_imshow(img2)\n",
        "  img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect \n",
        "  #cv2_imshow(img2)\n",
        "\n",
        "# return the face given a picture and the coords of the face\n",
        "def extractFace(pic, coords, r = 30):\n",
        "  return pic[coords.top()-r:coords.bottom()+r, coords.left()-r:coords.right()+r]\n",
        "\n",
        "def shape_to_np(shape, dtype=\"int\"):\n",
        "\t# initialize the list of (x, y)-coordinates\n",
        "\tcoords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
        "\n",
        "\t# loop over all facial landmarks and convert them\n",
        "\t# to a 2-tuple of (x, y)-coordinates\n",
        "\tfor i in range(0, shape.num_parts):\n",
        "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "\n",
        "\t# return the list of (x, y)-coordinates\n",
        "\treturn coords\n",
        "\n",
        "def shape_to_list(shape, dtype=\"int\"):\n",
        "\t# initialize the list of (x, y)-coordinates\n",
        "\tcoords = []\n",
        "\n",
        "\t# loop over all facial landmarks and convert them\n",
        "\t# to a 2-tuple of (x, y)-coordinates\n",
        "\tfor i in range(0, shape.num_parts):\n",
        "\t\tcoords.append((shape.part(i).x, shape.part(i).y))\n",
        "\n",
        "\t# return the list of (x, y)-coordinates\n",
        "\treturn coords\n",
        "\n",
        "def calculateDistance(x1,y1,x2,y2):  \n",
        "     dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)  \n",
        "     return dist \n",
        "\n",
        "# calculates the orientation_sum for each picture\n",
        "def calc_orientation_sums(pics, persons):\n",
        "  # create list with base score 0 and same size as pics\n",
        "  orientation_sums = []\n",
        "  for i in range(len(pics)):\n",
        "    orientation_sums.append(0)\n",
        "\n",
        "  # add orientation of each face to the picture orientation score\n",
        "  for person in persons:\n",
        "    for face in person.faces:\n",
        "      orientation_sums[face.picture_index] += face.score_orientation\n",
        "\n",
        "  return orientation_sums\n",
        "\n",
        "def extract_index_nparray(nparray):\n",
        "    index = None\n",
        "    for num in nparray[0]:\n",
        "        index = num\n",
        "        break\n",
        "    return index\n",
        "  \n",
        "# filenames\n",
        "landmarks_filename = \"shape_predictor_68_face_landmarks.dat\"\n",
        "facerecognition_filename = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
        "\n",
        "# TODO: fill pictures with filenames\n",
        "# upload pictures \n",
        "cv_pictures = [cv_img.copy() for cv_img in imgs]\n",
        "dlib_pictures = [cv2.cvtColor(cv_img,cv2.COLOR_BGR2RGB) for cv_img in cv_pictures]\n",
        "\n",
        "# init face detection and landmarks\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "face_landmarks = dlib.shape_predictor(landmarks_filename)\n",
        "face_recognition = dlib.face_recognition_model_v1(facerecognition_filename)\n",
        "face_cascade_smile = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
        "\n",
        "# list of every unique person\n",
        "persons = []\n",
        "\n",
        "# iterate each picture and search for faces\n",
        "for pic_idx, picture in enumerate(dlib_pictures):\n",
        "  # detect faces in the image\n",
        "  faces = face_detector(picture, 0)\n",
        "\n",
        "  # TODO: evlt Schleife angucken, was genau ist d?\n",
        "  # d is the rectangle of the face\n",
        "  # get landmarks of each face\n",
        "  # get id for each face\n",
        "  for k,d in enumerate(faces):\n",
        "    roi = extractFace(picture, d)\n",
        "    height, width, notneeded = roi.shape\n",
        "    landmarks = face_landmarks(roi,dlib.rectangle(0,0,width,height))\n",
        "    face_id = face_recognition.compute_face_descriptor(roi,landmarks)\n",
        "\n",
        "    # check if person is already in persons list\n",
        "    person = next((person for person in persons if person.faceVectorMatches(face_id)), None)\n",
        "    if person is None:\n",
        "      person = Person(face_id)\n",
        "      persons.append(person)\n",
        "\n",
        "    face = Face(roi, pic_idx, landmarks,d)\n",
        "    face.calc_scores()\n",
        "    face.calc_face_mask()\n",
        "    person.faces.append(face) \n",
        "    \n",
        "# Output plots\n",
        "for person in persons:\n",
        "  print(len(person.faces))\n",
        "  person.normalize_scores()\n",
        "  person.faces.sort(key=lambda face:face.score_all,reverse=True)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=1,ncols=len(person.faces),figsize=(15,15))\n",
        "  for i,a in enumerate(ax):\n",
        "    a.imshow(person.faces[i].picture_data)\n",
        "    a.set_title(person.faces[i].scores_str())\n",
        "    a.axis(\"off\")\n",
        "\n",
        "  plt.show()\n",
        "  print(\"---------\")\n",
        "\n",
        "# get orientation sums, one sum for each pic\n",
        "orientation_sums = calc_orientation_sums(cv_pictures,persons)\n",
        "# sort dlib pictures based on these scores\n",
        "sorted_pics = [cv_pictures for _, cv_pictures in sorted(zip(orientation_sums,cv_pictures), key=lambda pair: pair[0],reverse=True)]\n",
        "# sort orientation sums\n",
        "orientation_sums.sort(reverse=True)\n",
        "# output picture list, only needed for debugging\n",
        "if False == True:\n",
        "  fig, ax = plt.subplots(nrows=1,ncols=len(sorted_pics),figsize=(100,100))\n",
        "  for i,a in enumerate(ax):\n",
        "    a.imshow(sorted_pics[i])\n",
        "    a.set_title(orientation_sums[i])\n",
        "    a.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "# first picture of sorted_pics is the one with the highest orientation score, because its sorted \n",
        "base_picture = sorted_pics[0]\n",
        "height, width, notneeded = base_picture.shape\n",
        "cv2_imshow(cv2.resize(base_picture,(int(width/4),int(height/4))))\n",
        "\n",
        "# face swap\n",
        "\n",
        "# get dst_pic_index\n",
        "dst_pic_index = None\n",
        "for idx, pic in enumerate(cv_pictures):\n",
        "  if pic is base_picture:\n",
        "    dst_pic_index =  idx\n",
        "\n",
        "for person in persons:\n",
        "  # get src face\n",
        "  src_face = person.faces[0]\n",
        "  #src_face_img = cv2.cvtColor(src_face.picture_data, cv2.COLOR_BGR2RGB)\n",
        "  print(\"SRC FACE:\")\n",
        "  cv2_imshow(cv2.cvtColor(src_face.picture_data,cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  # get dst_face\n",
        "  dst_face_test = person.getFaceFromPic(dst_pic_index)\n",
        "  dst_face = base_picture\n",
        "  #dst_face_img = cv2.cvtColor(dst_face.picture_data, cv2.COLOR_BGR2RGB)\n",
        "  #print(\"DST FACE:\")\n",
        "  #cv2_imshow(cv2.cvtColor(dst_face.picture_data,cv2.COLOR_RGB2BGR))\n",
        "\n",
        "  if src_face.picture_data is dst_face_test.picture_data:\n",
        "    print(\"its the same face :(\")\n",
        "    continue\n",
        "\n",
        "  src_face.delauney_triangulation()\n",
        "  triangles = src_face.triangles\n",
        "\n",
        "  landmarks1 = shape_to_np(src_face.landmarks,dtype=np.int32)\n",
        "  #landmarks2 = shape_to_np(dst_face.landmarks,dtype=np.int32)\n",
        "  landmarks2 = dst_face_test.landmarksToFullSize()\n",
        "\n",
        "  hullTest = cv2.convexHull(landmarks2)\n",
        "  cv2.fillConvexPoly(dst_face,hullTest,(255,0,0))\n",
        "  cv2_imshow(dst_face)\n",
        "\n",
        "  indexes_triangles = []\n",
        "  for t in triangles:\n",
        "    pt1 = (t[0], t[1])\n",
        "    pt2 = (t[2], t[3])\n",
        "    pt3 = (t[4], t[5])\n",
        "\n",
        "    index_pt1 = np.where((landmarks1 == pt1).all(axis=1))\n",
        "    index_pt1 = extract_index_nparray(index_pt1)\n",
        "\n",
        "    index_pt2 = np.where((landmarks1 == pt2).all(axis=1))\n",
        "    index_pt2 = extract_index_nparray(index_pt2)\n",
        "\n",
        "    index_pt3 = np.where((landmarks1 == pt3).all(axis=1))\n",
        "    index_pt3 = extract_index_nparray(index_pt3)\n",
        "\n",
        "    if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
        "        triangle = [index_pt1, index_pt2, index_pt3]\n",
        "        indexes_triangles.append(triangle)\n",
        "  \n",
        "  t1 = []\n",
        "  t2 = []\n",
        "  #get points for img1, img2 corresponding to the triangles\n",
        "  for triangle_index in indexes_triangles:\n",
        "    t1_p1 = landmarks1[triangle_index[0]]\n",
        "    t1_p2 = landmarks1[triangle_index[1]]\n",
        "    t1_p3 = landmarks1[triangle_index[2]]\n",
        "    triangle1 = np.array([t1_p1,t1_p2,t1_p3])\n",
        "\n",
        "    t2_p1 = landmarks2[triangle_index[0]]\n",
        "    t2_p2 = landmarks2[triangle_index[1]]\n",
        "    t2_p3 = landmarks2[triangle_index[2]]\n",
        "    triangle2 = np.array([t2_p1,t2_p2,t2_p3])\n",
        "\n",
        "    t1.append(triangle1)\n",
        "    t2.append(triangle2)\n",
        "\n",
        "  for i in range(0,len(indexes_triangles)):\n",
        "    warpTriangle(src_face.picture_data, dst_face, t1[i], t2[i])\n",
        "\n",
        "  # Calculate Mask\n",
        "\n",
        "  mask = dst_face_test.mask\n",
        "\n",
        "  #cv2.fillConvexPoly(mask, np.int32(mask), (255, 255, 255))\n",
        "  \n",
        "  hull2 = landmarks2[:22]\n",
        "  hull2 = cv2.convexHull(hullArray)\n",
        "\n",
        "  #r = cv2.boundingRect(np.float32([hull2]))    \n",
        "  x = dst_face_test.coords.left()\n",
        "  y = dst_face_test.coords.top()\n",
        "  w =dst_face_test.coords.right()-x\n",
        "  h=dst_face_test.coords.bottom()-y\n",
        "  #r = cv2.boundingRect([(x,y),(w,h)])\n",
        "  center = ((x+int(w/2), y+int(h/2)))\n",
        "  #center = (int((x+x+w)/2),int((y+y+h)/2))    \n",
        "\n",
        "  # Clone seamlessly.\n",
        "  output = cv2.seamlessClone(np.uint8(dst_face_test.picture_data), base_picture, mask, center, cv2.NORMAL_CLONE)\n",
        "  base_picture = output\n",
        "  print(\"DURCHLAUF NEU ----------------\")\n",
        "\n",
        "print(\"FINAL PICTURE:\")\n",
        "width, height, _ = base_picture.shape\n",
        "cv2_imshow(base_picture)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}